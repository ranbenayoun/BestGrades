{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64f1fa09",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Best Grades \n",
    "#### Project by Ran Benayoun"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422b5c6a",
   "metadata": {},
   "source": [
    "## Project Description\n",
    "\n",
    "This project scrapes the histogram database from Cheesefork's GitHub repository.\n",
    "\n",
    "It enables analysis of:\n",
    "- The **average median grade** for each course\n",
    "- The **maximum grade** recorded in each course\n",
    "\n",
    "## Limitations\n",
    "\n",
    "- The statistics are based only on **available histograms**. Courses with no histograms (typically those with under 10 students or no shared data) are **not included** in the analysis.\n",
    "- **Course numbers change occasionally**, which can result in data loss or duplication.\n",
    "- In **2024**, the Technion changed course numbers from 6 digits to 7 or 8 digits. This created inconsistencies in the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82607d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the imports needed for the script to function properly\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f017bc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defing functions needed for the script\n",
    "\n",
    "def find_6_digit_sequences(input_string):\n",
    "    \"\"\"\n",
    "    for catalogs older than 2024\n",
    "    Finds all unique 6-digit sequences in a given string.\n",
    "\n",
    "    Args:\n",
    "        input_string (str): The string to search for 6-digit sequences.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of unique 6-digit sequences found in the input string.\n",
    "    \"\"\"\n",
    "    # Define the regex pattern to match 6-digit sequences\n",
    "    pattern = r'\\b\\d{6}\\b'\n",
    "    \n",
    "    # Find all matches using findall() method\n",
    "    sequences = re.findall(pattern, input_string)\n",
    "    \n",
    "    return sequences\n",
    "\n",
    "def find_7_digit_sequences(input_string):\n",
    "    \"\"\"\n",
    "    for catalogs newer than 2024\n",
    "    Finds all unique 7-digit sequences in a given string.\n",
    "\n",
    "    Args:\n",
    "        input_string (str): The string to search for 76-digit sequences.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of unique 7-digit sequences found in the input string.\n",
    "    \"\"\"\n",
    "    # Define the regex pattern to match 7-digit sequences\n",
    "    pattern = r'\\b\\d{7}\\b'\n",
    "    \n",
    "    # Find all matches using findall() method\n",
    "    sequences = re.findall(pattern, input_string)\n",
    "    \n",
    "    return sequences\n",
    "\n",
    "def clean_string(input_string):\n",
    "    \"\"\"\n",
    "    Cleans a string by removing double quotes, single quotes, new lines, \n",
    "    carriage returns, and excessive spaces.\n",
    "\n",
    "    Args:\n",
    "        input_string (str): The string to be cleaned.\n",
    "\n",
    "    Returns:\n",
    "        str: The cleaned string.\n",
    "    \"\"\"\n",
    "    # Replace unwanted characters\n",
    "    cleaned_string = input_string.replace('\"', '').replace(\"'\", '').replace('\\n', ' ').replace('\\r', ' ')\n",
    "    \n",
    "    # Remove leading and trailing whitespace\n",
    "    cleaned_string = cleaned_string.strip()\n",
    "    \n",
    "    # Remove excessive spaces between words\n",
    "    cleaned_string = ' '.join(cleaned_string.split())\n",
    "    \n",
    "    return cleaned_string\n",
    "\n",
    "# Loading the updated catalogs to verify\n",
    "def load_catalog_file(filename):\n",
    "    \"\"\"\n",
    "    Loads a JSON file and returns the catalog data as a dictionary.\n",
    "\n",
    "    Args:\n",
    "        filename (str): The name of the JSON file to be loaded.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the catalog data.\n",
    "    \"\"\"\n",
    "    if os.path.exists(filename):\n",
    "        with open(filename, 'r', encoding='utf-8') as f:\n",
    "            catalogs = json.load(f)\n",
    "        return catalogs\n",
    "    else:\n",
    "        print(f\"File '{filename}' not found.\")\n",
    "        return {}\n",
    "\n",
    "def plot_bar_chart_with_trendline(average_medians, save_path=None):\n",
    "    \"\"\"\n",
    "    Plots a bar chart of the average medians with a trendline.\n",
    "    \n",
    "    Args:\n",
    "        average_medians (dict): Dictionary with course numbers as keys and average median values as values.\n",
    "        save_path (str, optional): If provided, saves the figure to the given path.\n",
    "    \"\"\"\n",
    "    # Filter out None values\n",
    "    courses = [course for course, median in average_medians.items() if median is not None]\n",
    "    medians = [median for median in average_medians.values() if median is not None]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(courses, medians, color='skyblue', label='Average Median')\n",
    "\n",
    "    # Add trendline\n",
    "    x = np.arange(len(courses))\n",
    "    z = np.polyfit(x, medians, 1)\n",
    "    p = np.poly1d(z)\n",
    "    plt.plot(courses, p(x), \"r--\", label='Trendline')\n",
    "\n",
    "    plt.title('Bar Plot of Average Medians by Course Number')\n",
    "    plt.xlabel('Course Number')\n",
    "    plt.ylabel('Average Median')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(axis='y')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "        print(f\"Figure saved to {save_path}\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6915df8",
   "metadata": {},
   "source": [
    "Adding catalog entries with points through the scripts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5cf29875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25d5f926bd064b6194ede0a4a927dc2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Catalog name:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fccabd1cc5e24ba6bbc8f1b3e5d0f8ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='', description='Courses:', layout=Layout(height='300px', width='100%'), placeholder='Paste cou…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d71a2d4f07504582bc23628f2a06438a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Save Catalog', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebb7afc3f18044849cad0c7215595764",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "def add_to_catalog_file(filename):\n",
    "    if os.path.exists(filename):\n",
    "        with open(filename, 'r', encoding='utf-8') as f:\n",
    "            existing_catalogs = json.load(f)\n",
    "    else:\n",
    "        existing_catalogs = {}\n",
    "\n",
    "    # Catalog name input\n",
    "    catalog_name_widget = widgets.Text(description='Catalog name:')\n",
    "    display(catalog_name_widget)\n",
    "\n",
    "    # Textarea for multiline input\n",
    "    text_area = widgets.Textarea(\n",
    "        value='',\n",
    "        placeholder='Paste course data here...',\n",
    "        description='Courses:',\n",
    "        layout=widgets.Layout(width='100%', height='300px')\n",
    "    )\n",
    "    display(text_area)\n",
    "\n",
    "    # Button to process and save\n",
    "    save_button = widgets.Button(description=\"Save Catalog\")\n",
    "    output = widgets.Output()\n",
    "    display(save_button, output)\n",
    "\n",
    "    def on_button_click(b):\n",
    "        catalog_name = catalog_name_widget.value.strip()\n",
    "        input_text = text_area.value\n",
    "        lines = input_text.strip().split('\\n')\n",
    "\n",
    "        current_catalog_data = {}\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            match = re.search(r'(\\d+).*?(\\d+\\.\\d+)$', line)\n",
    "            if match:\n",
    "                course_number = '0' + match.group(1)\n",
    "                try:\n",
    "                    points = float(match.group(2))\n",
    "                    current_catalog_data[course_number] = points\n",
    "                except ValueError:\n",
    "                    print(f\"Warning: Could not parse points in: '{line}'\")\n",
    "            else:\n",
    "                print(f\"Warning: Format not recognized: '{line}'\")\n",
    "\n",
    "        existing_catalogs[catalog_name] = current_catalog_data\n",
    "\n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            json.dump(existing_catalogs, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "        with output:\n",
    "            output.clear_output()\n",
    "            print(f\"Catalog '{catalog_name}' saved to {filename}\")\n",
    "            print(current_catalog_data)\n",
    "\n",
    "    save_button.on_click(on_button_click)\n",
    "\n",
    "add_to_catalog_file(\"Catalogs_points.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64dc763",
   "metadata": {},
   "source": [
    "This code goes through the list of courses and extract all the stats from Cheesfork's GitHub while showing a progress bar - got to be patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ff0a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_finals_statistics(course_numbers, access_token):\n",
    "    \"\"\"\n",
    "    Fetches the finals statistics for the given course numbers from GitHub.\n",
    "\n",
    "    Args:\n",
    "        course_numbers (list of str): List of course numbers to fetch statistics for.\n",
    "        access_token (str): GitHub access token for authentication.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the statistics for each course.\n",
    "    \"\"\"\n",
    "    base_url = \"https://api.github.com/repos/michael-maltsev/technion-histograms/contents/\"\n",
    "    headers = {'Authorization': f'token {access_token}'}\n",
    "    all_statistics = {}\n",
    "\n",
    "    for course_number in tqdm(course_numbers):\n",
    "        course_url = f\"{base_url}{course_number}?ref=main\"\n",
    "        try:\n",
    "            response = requests.get(course_url, headers=headers)\n",
    "            response.raise_for_status()\n",
    "            contents = response.json()\n",
    "\n",
    "            course_data = {'folders': {}}\n",
    "\n",
    "            for item in contents:\n",
    "                if item['type'] == 'dir':\n",
    "                    folder_name = item['name']\n",
    "                    finals_json_url = f\"https://raw.githubusercontent.com/michael-maltsev/technion-histograms/main/{course_number}/{folder_name}/Finals.json\"\n",
    "                    finals_response = requests.head(finals_json_url)\n",
    "                    if finals_response.status_code == 200:\n",
    "                        finals_data = requests.get(finals_json_url).json()\n",
    "                        course_data['folders'][folder_name] = {\n",
    "                            'average': finals_data.get('average'),\n",
    "                            'median': finals_data.get('median')\n",
    "                        }\n",
    "\n",
    "            all_statistics[course_number] = course_data\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error fetching data for course {course_number}: {e}\")\n",
    "        sleep(0.2)\n",
    "    return all_statistics\n",
    "\n",
    "def write_to_csv(statistics):\n",
    "    \"\"\"\n",
    "    Writes the finals statistics to a CSV file.\n",
    "\n",
    "    Args:\n",
    "        statistics (dict): The statistics data to write to the CSV.\n",
    "        filename (str): The name of the CSV file to write to.\n",
    "    \"\"\"\n",
    "    filename = input(\"Enter the filename to save the CSV: \")\n",
    "    filename = filename + \".csv\"\n",
    "    with open(filename, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Course Number', 'Semester', 'Average', 'Median'])\n",
    "        for course_number, data in statistics.items():\n",
    "            for folder, stats in data['folders'].items():\n",
    "                writer.writerow([course_number, folder, stats['average'], stats['median']])\n",
    "        writer.writerow(['Course Number', 'Average of Medians'])\n",
    "        #calculate average of medians to put at the end of the CSV\n",
    "        average_medians = calculate_average_median(statistics)\n",
    "        for course_number in average_medians:\n",
    "            writer.writerow([course_number, average_medians[course_number]])\n",
    "    print(f\"Data has been written to {filename}\")\n",
    "\n",
    "def calculate_average_median(statistics):\n",
    "    \"\"\"\n",
    "    Calculates the average of the median values for each course.\n",
    "\n",
    "    Args:\n",
    "        statistics (dict): The statistics data containing median values.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary with course numbers as keys and their average median values as values.\n",
    "    \"\"\"\n",
    "    average_medians = {}\n",
    "    for course_number, data in statistics.items():\n",
    "        medians = []\n",
    "        for folder in data['folders'].values():\n",
    "            median_value = folder['median']\n",
    "            if median_value is not None:\n",
    "                try:\n",
    "                    median_value = round(float(median_value), 2)  # Round to 2 decimal places\n",
    "                    medians.append(median_value)\n",
    "                except ValueError:\n",
    "                    # Skip non-numeric median values silently\n",
    "                    continue\n",
    "        \n",
    "        if medians:\n",
    "            average_median = round(sum(medians) / len(medians), 2)  # Round to 2 decimal places\n",
    "        else:\n",
    "            average_median = None\n",
    "        average_medians[course_number] = average_median\n",
    "\n",
    "    return average_medians\n",
    "\n",
    "import json\n",
    "\n",
    "def calculate_gpa_from_medians(average_medians, catalog_file, catalog_name):\n",
    "    \"\"\"\n",
    "    Calculates GPA using average medians and course credit points.\n",
    "\n",
    "    Args:\n",
    "        average_medians (dict): Dictionary with course numbers as keys and average median values.\n",
    "        catalog_file (str): Path to Catalogs_points.json.\n",
    "        catalog_name (str): Name of the catalog to use from the file.\n",
    "\n",
    "    Returns:\n",
    "        float: Calculated GPA rounded to 2 decimal places.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(catalog_file, 'r', encoding='utf-8') as f:\n",
    "            catalogs = json.load(f)\n",
    "    except (IOError, json.JSONDecodeError) as e:\n",
    "        print(f\"Error reading catalog file: {e}\")\n",
    "        return None\n",
    "\n",
    "    if catalog_name not in catalogs:\n",
    "        print(f\"Catalog '{catalog_name}' not found in {catalog_file}\")\n",
    "        return None\n",
    "\n",
    "    catalog_points = catalogs[catalog_name]\n",
    "\n",
    "    total_weighted = 0.0\n",
    "    total_points = 0.0\n",
    "\n",
    "    for course_number, average_median in average_medians.items():\n",
    "        if average_median is None:\n",
    "            continue\n",
    "        if course_number not in catalog_points:\n",
    "            continue\n",
    "        points = catalog_points[course_number]\n",
    "        total_weighted += average_median * points\n",
    "        total_points += points\n",
    "\n",
    "    if total_points == 0:\n",
    "        print(\"No valid course points found for GPA calculation.\")\n",
    "        return None\n",
    "\n",
    "    gpa = round(total_weighted / total_points, 2)\n",
    "    return gpa\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8dcb23",
   "metadata": {},
   "source": [
    "Set up your personal access token from GitHub - this next code will test if it's valid. if not you'll be limited to get 60 courses per hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc97f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid.\n"
     ]
    }
   ],
   "source": [
    "access_token = ''  # Replace with your actual access token\n",
    "\n",
    "# Test the token validity by making a simple API request\n",
    "test_url = \"https://api.github.com/user\"\n",
    "test_response = requests.get(test_url, headers={'Authorization': f'token {access_token}'})\n",
    "\n",
    "if test_response.status_code == 200:\n",
    "    print(\"Token is valid.\")\n",
    "else:\n",
    "    print(f\"Invalid token. Status code: {test_response.status_code}\")\n",
    "    print(test_response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c267b1d1",
   "metadata": {},
   "source": [
    "# OR \n",
    "add directly a string to the catalog file, and the entry will parse through functions to extract the course numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8658d2-6644-445e-b464-5c8be61ddd36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#loaging the updated catalogs to verify\n",
    "#catalog = load_catalog_file(\"catalogs.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0973800",
   "metadata": {},
   "source": [
    "View the content of the catalogs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a56c5650",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for catalog_name, catalog_content in catalog.items():\n",
    "#    print(f\"{catalog_name}: {catalog_content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c059486",
   "metadata": {},
   "source": [
    "Load the BME mandatory courses and add a leading \"0\" for formatting according to Cheesfork data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0af9c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00440102', '01040065', '01040042', '01140071', '01250001', '01340058', '03340021', '01040042', '01040018', '01040065', '01040016', '01040013', '01040038', '01040136', '01140052', '01240801', '02340128', '00440105', '01040214', '01040215', '01040220', '01240503', '01340019', '03340274', '03240033', '00440131', '01040034', '03340221', '03340222', '03360537', '01340113', '03340009', '03340011', '03350010', '03360022', '03360100', '03340023', '03350001', '03340014', '03350002', '03360026', '03350015', '03350003']\n"
     ]
    }
   ],
   "source": [
    "# hova_2024 = find_7_digit_sequences(clean_string(catalog['hova_2024']))\n",
    "# hova_2024 = [\"0\" + s for s in hova_2024]\n",
    "# print(hova_2024)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b8b06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Helps to know what changed each year\n",
    "# def compare_lists(list1, list2):\n",
    "#     differences = {\n",
    "#         \"only_in_list1\": [item for item in list1 if item not in list2],\n",
    "#         \"only_in_list2\": [item for item in list2 if item not in list1],\n",
    "#         \"in_both\": [item for item in list1 if item in list2]\n",
    "#     }\n",
    "#     return differences\n",
    "\n",
    "# hova2018 = find_6_digit_sequences(clean_string(catalog['hova_2018']))\n",
    "# hova2019 = find_6_digit_sequences(clean_string(catalog['hova_2019']))\n",
    "# hova2020 = find_6_digit_sequences(clean_string(catalog['hova_2020']))\n",
    "# hova2021 = find_6_digit_sequences(clean_string(catalog['hova_2021']))\n",
    "# hova2022 = find_6_digit_sequences(clean_string(catalog['hova_2022']))\n",
    "# hova2023 = find_6_digit_sequences(clean_string(catalog['hova_2023']))\n",
    "\n",
    "# #compare_lists(hova2019, hova2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad55347c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Setting up \"Megamot\" course lists for core courses (have to pick at least 2) and the rest of the courses.\n",
    "# #This list fits the catalog in 2023. any catalog after 2024 includes \"Biophysics\" and have very different lists.\n",
    "\n",
    "# #loading biomechanics courses from the catalog\n",
    "# mech = find_6_digit_sequences(clean_string(catalog['biomechanics']))\n",
    "# #splitting into mandetory and electives - Biomechanics\n",
    "# mech_core = mech[:6]\n",
    "# mech_rest = mech[6:]\n",
    "\n",
    "# #Setting up signal processing course lists for core courses (have to pick at least 2) and the rest of the courses.\n",
    "# sig_core = [\"336020\",\"336023\",\"336027\",\"336208\",\"336326\",\"336502\",\"336522\",\"336533\"]\n",
    "# sig_rest =[\"336325\",\"336504\",\"336521\",\"336536\",\"336538\",\"336540\",\"336544\",\"336545\",\"336546\",\"336547\",\"336549\",\"336550\",\"034033\",\"044101\",\"044198\",\"044202\",\"046195\",\"046197\",\"046200\",\"046201\",\"046211\",\"046332\",\"046745\",\"046746\",\"236523\",\"236781\"]\n",
    "# #splitting into mandetory and electives - Tissue engineering\n",
    "# rekamot = find_6_digit_sequences(clean_string(catalog['Tissue']))\n",
    "# tissue_core = rekamot[:5]\n",
    "# tissue_rest = rekamot[5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30297c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/43 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▎ | 36/43 [01:54<00:11,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for course 03360100: 404 Client Error: Not Found for url: https://api.github.com/repos/michael-maltsev/technion-histograms/contents/03360100?ref=main\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [02:07<00:00,  2.97s/it]\n"
     ]
    }
   ],
   "source": [
    "# hova2024 = get_finals_statistics(hova_2024,access_token)\n",
    "# averages = calculate_average_median(hova2024)\n",
    "# print(averages)\n",
    "# plot_bar_chart_with_trendline(calculate_average_median(hova2024), \"average_medians_plot_2024.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab50dff2",
   "metadata": {},
   "source": [
    "the statistics does not include \"Physiology\" course (changed number, no histogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8790525a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Imaging courses:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 8/35 [00:09<00:25,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for course 03360209: 404 Client Error: Not Found for url: https://api.github.com/repos/michael-maltsev/technion-histograms/contents/03360209?ref=main\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [01:06<00:00,  1.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Biomechanics courses:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 17/23 [00:17<00:06,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for course 00360072: 404 Client Error: Not Found for url: https://api.github.com/repos/michael-maltsev/technion-histograms/contents/00360072?ref=main\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 19/23 [00:18<00:03,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for course 00360086: 404 Client Error: Not Found for url: https://api.github.com/repos/michael-maltsev/technion-histograms/contents/00360086?ref=main\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:28<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Biophysics courses:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:28<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Tissue courses:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 18/24 [00:13<00:03,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for course 00660121: 404 Client Error: Not Found for url: https://api.github.com/repos/michael-maltsev/technion-histograms/contents/00660121?ref=main\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:26<00:00,  1.09s/it]\n"
     ]
    }
   ],
   "source": [
    "# print(\"Processing Imaging courses:\")\n",
    "# imaging_course_numbers = list(imaging.keys())\n",
    "# imaging = get_finals_statistics(imaging_course_numbers, access_token)\n",
    "# ave_imaging = calculate_average_median(imaging)\n",
    "\n",
    "# print(\"\\nProcessing Biomechanics courses:\")\n",
    "# biomechanics_course_numbers = list(biomechanics.keys())\n",
    "# biomech = get_finals_statistics(biomechanics_course_numbers, access_token)\n",
    "# ave_biomech = calculate_average_median(biomech)\n",
    "\n",
    "# print(\"\\nProcessing Biophysics courses:\")\n",
    "# biophysics_course_numbers = list(biophysics.keys())\n",
    "# biophys = get_finals_statistics(biophysics_course_numbers, access_token)\n",
    "# ave_biophys = calculate_average_median(biophys)\n",
    "\n",
    "# print(\"\\nProcessing Tissue courses:\")\n",
    "# tissue_course_numbers = list(tissue.keys())\n",
    "# tissue = get_finals_statistics(tissue_course_numbers, access_token)\n",
    "# ave_tissue = calculate_average_median(tissue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fccf299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'03360021': 86.33,\n",
       " '03360402': 90.67,\n",
       " '03360517': 87.22,\n",
       " '03360528': 86.79,\n",
       " '03360529': 88.19,\n",
       " '03360326': 89.33,\n",
       " '03360404': None,\n",
       " '03360405': 90.25,\n",
       " '03360520': 89.5,\n",
       " '03360521': None,\n",
       " '03360538': 92.79,\n",
       " '03360544': 92.92,\n",
       " '03360548': None,\n",
       " '03360549': 94.0,\n",
       " '03360550': 95.5,\n",
       " '00540413': 88.4,\n",
       " '00660333': 90.0,\n",
       " '01340020': 79.3,\n",
       " '01340069': 88.0,\n",
       " '01340082': 84.45,\n",
       " '01340119': 83.67,\n",
       " '01340121': 87.78,\n",
       " '02760413': 81.25}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ave_tissue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "95cb8401",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = {'00440102': None,\n",
    " '01040065': 5.0,\n",
    " '01040042': 5.0,\n",
    " '01140071': 3.5,\n",
    " '01250001': 3.0,\n",
    " '01340058': 3.0,\n",
    " '03340021': 1.0,\n",
    " '01040018': 5.0,\n",
    " '01040016': 5.0,\n",
    " '01040013': 5.5,\n",
    " '01040038': 2.5,\n",
    " '01040136': 4.0,\n",
    " '01140052': 3.5,\n",
    " '01240801': 2.5,\n",
    " '02340128': 4.0,\n",
    " '00440105': 4.0,\n",
    " '01040214': 2.5,\n",
    " '01040215': 2.5,\n",
    " '01040220': 2.5,\n",
    " '01240503': 2.5,\n",
    " '01340019': 2.5,\n",
    " '03340274': 2.0,\n",
    " '03240033': 3.0,\n",
    " '00440131': 5.0,\n",
    " '01040034': 3.5,\n",
    " '03340221': 2.5,\n",
    " '03340222': 4.0,\n",
    " '03360537': 3.0,\n",
    " '01340113': 3.5,\n",
    " '03340009': 4.0,\n",
    " '03340011': 4.0,\n",
    " '03350010': 3.0,\n",
    " '03360022': 2.5,\n",
    " '03340023': 3.5,\n",
    " '03350001': 3.5,\n",
    " '03340014': 2.0,\n",
    " '03350002': 4.0,\n",
    " '03360026': None,\n",
    " '03350015': 3.0,\n",
    " '03350003': 2.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6cd29ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final calculated weighted average is: 81.82\n"
     ]
    }
   ],
   "source": [
    "# Course numbers to be dropped from the averages calculation\n",
    "courses_to_drop = ['03240033', '01040018', '01040016']\n",
    "\n",
    "# Initialize variables for weighted sum and total points\n",
    "weighted_sum = 0.0\n",
    "total_points = 0.0\n",
    "\n",
    "# Iterate through the averages dictionary\n",
    "for course_number, average in averages.items():\n",
    "    # Check if the course number should be dropped or if its average is None\n",
    "    if course_number in courses_to_drop or average is None:\n",
    "        continue\n",
    "\n",
    "    # Ensure the course number is a string for consistent key lookup\n",
    "    course_number_str = str(course_number)\n",
    "\n",
    "    # Check if the course number exists in the points dictionary\n",
    "    if course_number_str in points:\n",
    "        course_points = points[course_number_str]\n",
    "\n",
    "        # Only include courses with non-zero points in the calculation\n",
    "        if course_points > 0:\n",
    "            weighted_sum += (average * course_points)\n",
    "            total_points += course_points\n",
    "\n",
    "# Calculate the final weighted average\n",
    "final_weighted_average = 0.0\n",
    "if total_points > 0:\n",
    "    final_weighted_average = weighted_sum / total_points\n",
    "\n",
    "print(f\"The final calculated weighted average is: {final_weighted_average:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6c3e2995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "biomech = {'03360326': 2.5, '03360506': 2.5, '03360517': 2.5, '03360522': 3.0, '03360539': 2.5, '03360541': 2.5, '03360021': 2.5, '03360520': 2.5, '03360521': 3.5, '03360540': 2.5, '03360549': 3.0, '03360550': 2.5, '00340033': 3.0, '00350001': 2.5, '00350199': 3.0, '00360049': 2.5, '00360072': 3.0, '00360076': 3.0, '00360086': 3.0, '00360090': 3.0, '00840225': 4.0, '02360332': 2.0, '02360333': 3.0}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text_data = \"\"\"\n",
    "Biomechanics:\n",
    "3360326 םירטמרפ ךורעשו םינותנ חותינ 2 1 - 2.5\n",
    "3360506 תימוקיש הקינכמויב 2 1 - 2.5\n",
    "3360517 ויב - אתה לש הסדנה 2 1 - 2.5\n",
    "3360522 ויב תוכרעמב הרקבל אובמ - תויאופר 2 2 - 3.0\n",
    "3360539 המישנה תוכרעמב המירז 2 1 - 2.5\n",
    "3360541 תירלוקסווידרקה תכרעמב המירז 2 1 - 2.5\n",
    "3360021 וננ - יגולואירו הקינכמ 'לויבב םיקיקלח 2 1 - 2.5\n",
    "3360520 המקר יפילחתו םיידפוטרוא םילתש 2 1 - 2.5\n",
    "3360521 וידרקה 'עמ לש םייסדנה תונורקע 3 1 - 3.5\n",
    "3360540 בשחוממ יאופר רושכמ ןכת 2 1 - 2.5\n",
    "3360549 ףוציר תוקינכט DNA 2 2 - 3.0\n",
    "3360550 תיבושיח הקיזיפויב 2 1 - 2.5\n",
    "0340033 'מ תירמונ הזילנא 2 2 - 3.0\n",
    "0350001 הקיטובורל אובמ 2 1 - 2.5\n",
    "0350199 המירזה תרותב בשחמה שומיש 2 2 - 3.0\n",
    "0360049 הקיטסונגאידו הרקבל תויבצע תותשר 2 1 - 2.5\n",
    "0360072 הקיטובורו הקינכמויבב הקיטמטניק 3 - - 3.0\n",
    "0360076 וננב הקיטניק ורטקלא - ורקימו - המירז 3 - - 3.0\n",
    "0360086 נורקימ םינקתהב רבעמ תועפותו המירז 2 1 1 3.0\n",
    "0360090 םיאת לש תינכמ השיחו הקינכמויב 3 -- - 3.0\n",
    "0840225 הקימניד 3 2 - 4.0\n",
    "2360332 םירבדה לש טנרטניאה - תויגולונכט 2 - - 2.0\n",
    "2360333 םירבדה לש טנרטניאב טקיורפ 2 - 4 3.0\n",
    "\"\"\"\n",
    "\n",
    "# Current category being processed\n",
    "category_name = input(\"Enter the category name for the first course: \")\n",
    "# Create a dictionary with the category name as the variable name\n",
    "globals()[category_name] = {}\n",
    "current_category = globals()[category_name]\n",
    "# Split the text into lines\n",
    "lines = text_data.strip().split('\\n')\n",
    "\n",
    "for line in lines:\n",
    "    line = line.strip()\n",
    "    # Skip empty lines\n",
    "    if not line:\n",
    "        continue\n",
    "\n",
    "    # Regex to find the course number (first group of digits) and the points (last float)\n",
    "    match = re.search(r'(\\d+).*?(\\d+\\.\\d+)$', line)\n",
    "    if match:\n",
    "        course_number = match.group(1)\n",
    "        points_str = match.group(2)\n",
    "        course_number = '0' + course_number\n",
    "\n",
    "        try:\n",
    "            points = float(points_str)\n",
    "            current_category[course_number] = points\n",
    "        except ValueError:\n",
    "            print(f\"Warning: Could not parse points for line: {line}\")\n",
    "    else:\n",
    "        # This handles cases where a line might not contain a course number and points\n",
    "        # but isn't a category header (e.g., empty lines within a category, or other descriptive text)\n",
    "        pass # Silently ignore lines that don't match the pattern\n",
    "\n",
    "print(f\"{category_name} =\", current_category)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a514d379",
   "metadata": {},
   "source": [
    "We can't conclude much from that stats, but we can debate about that :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113676f4",
   "metadata": {},
   "source": [
    "Now i'm gonna find out which course had an exam that no one could ace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21d1b5cc-2ec8-4aff-addc-20616297a3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_statistics(course_numbers, access_token):\n",
    "    \"\"\"\n",
    "    Fetches the maximum grade statistics for the given course numbers from GitHub,\n",
    "    considering \"Exam_A.json\" and \"Exam_B.json\", excluding grades of 100.\n",
    "\n",
    "    Args:\n",
    "        course_numbers (list of str): List of course numbers to fetch statistics for.\n",
    "        access_token (str): GitHub access token for authentication.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the maximum grade statistics for each course.\n",
    "    \"\"\"\n",
    "    statistics = {}\n",
    "    base_url = \"https://api.github.com/repos/michael-maltsev/technion-histograms/contents/\"\n",
    "    headers = {'Authorization': f'token {access_token}'}\n",
    "\n",
    "    for course_number in tqdm(course_numbers):\n",
    "        course_url = f\"{base_url}{course_number}?ref=main\"\n",
    "        try:\n",
    "            response = requests.get(course_url, headers=headers)\n",
    "            response.raise_for_status()\n",
    "            folders = response.json()\n",
    "\n",
    "            course_statistics = {\"Exam_A\": {}, \"Exam_B\": {}}\n",
    "            for folder in folders:\n",
    "                if folder['type'] == 'dir':\n",
    "                    folder_name = folder['name']\n",
    "                    for exam in [\"Exam_A.json\", \"Exam_B.json\"]:\n",
    "                        exam_key = exam.split('.')[0]  # Either \"Exam_A\" or \"Exam_B\"\n",
    "                        exam_url =f\"https://raw.githubusercontent.com/michael-maltsev/technion-histograms/main/{course_number}/{folder_name}/{exam}\"\n",
    "                        response = requests.get(exam_url, headers=headers)\n",
    "                        if response.status_code == 200:\n",
    "                            exam_data = response.json()\n",
    "                            max_grade = exam_data.get(\"max\")\n",
    "                            if max_grade and max_grade != 100:\n",
    "                                if folder_name not in course_statistics[exam_key]:\n",
    "                                    course_statistics[exam_key][folder_name] = max_grade\n",
    "                                else:\n",
    "                                    course_statistics[exam_key][folder_name] = max(max_grade, course_statistics[exam_key][folder_name])\n",
    "            statistics[course_number] = course_statistics\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error fetching data for course {course_number}: {e}\")\n",
    "    sleep(0.2)\n",
    "    return statistics\n",
    "\n",
    "def write_max_statistics_to_csv(statistics, filename):\n",
    "    \"\"\"\n",
    "    Writes the maximum grade statistics to a CSV file.\n",
    "\n",
    "    Args:\n",
    "        statistics (dict): A dictionary containing the maximum grade statistics for each course.\n",
    "        filename (str): The name of the CSV file to be created.\n",
    "    \"\"\"\n",
    "    with open(filename, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Course Number\", \"Folder\", \"Exam\", \"Max Grade\"])\n",
    "\n",
    "        for course_number, exams in statistics.items():\n",
    "            # Get all unique folders\n",
    "            all_folders = set()\n",
    "            for exam_key, folders in exams.items():\n",
    "                all_folders.update(folders.keys())\n",
    "            \n",
    "            # Write data for each folder\n",
    "            for folder_name in all_folders:\n",
    "                for exam_key in ['Exam_A', 'Exam_B']:\n",
    "                    if exam_key in exams and folder_name in exams[exam_key]:\n",
    "                        max_grade = exams[exam_key][folder_name]\n",
    "                        writer.writerow([course_number, folder_name, exam_key, max_grade])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7eea8cd-5d0f-4750-aa80-c5cfb0d9e83e",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████████████████████████████████████████████████████████████▎                | 34/43 [08:53<01:05,  7.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for course 034057: 404 Client Error: Not Found for url: https://api.github.com/repos/michael-maltsev/technion-histograms/contents/034057?ref=main\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|████████████████████████████████████████████████████████████████████████▌       | 39/43 [09:22<00:19,  4.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for course 034382: 404 Client Error: Not Found for url: https://api.github.com/repos/michael-maltsev/technion-histograms/contents/034382?ref=main\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 43/43 [09:39<00:00, 13.47s/it]\n"
     ]
    },
    {
     "data": {
      "application/javascript": "$(document).ready(\n    function() {\n        function appendUniqueDiv(){\n            // append a div with our uuid so we can check that it's already\n            // been sent and avoid duplicates on page reload\n            var notifiedDiv = document.createElement(\"div\")\n            notifiedDiv.id = \"4b093584-e046-4ee3-bad3-c880c41a55f7\"\n            element.append(notifiedDiv)\n        }\n\n        // only send notifications if the pageload is complete; this will\n        // help stop extra notifications when a saved notebook is loaded,\n        // which during testing gives us state \"interactive\", not \"complete\"\n        if (document.readyState === 'complete') {\n            // check for the div that signifies that the notification\n            // was already sent\n            if (document.getElementById(\"4b093584-e046-4ee3-bad3-c880c41a55f7\") === null) {\n                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"Cell execution has finished!\"};\n                if (Notification.permission !== 'denied') {\n                    if (Notification.permission !== 'granted') { \n                        Notification.requestPermission(function (permission) {\n                            if(!('permission' in Notification)) {\n                                Notification.permission = permission\n                            }\n                        })\n                    }\n                    if (Notification.permission === 'granted') {\n                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n                    appendUniqueDiv()\n                    notification.onclick = function () {\n                        window.focus();\n                        this.close();\n                        };\n                    } \n                }     \n            }\n        }\n    }\n)\n",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "write_max_statistics_to_csv(get_max_statistics(find_6_digit_sequences(clean_string(catalog['mechonot'])), access_token), \"MechMax.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
